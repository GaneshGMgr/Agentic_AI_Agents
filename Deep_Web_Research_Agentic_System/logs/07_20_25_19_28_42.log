[2025-07-20 19:28:45,806] 60 backend.logger.logger - INFO - Received query: Generate a report using academic studies on climate change.
[2025-07-20 19:28:45,806] 61 backend.logger.logger - INFO - Selected model: ollama-llama3
[2025-07-20 19:28:45,807] 69 backend.logger.logger - INFO - Using model provider: ollama-llama3 (llama3.2:latest)
[2025-07-20 19:29:08,320] 110 backend.logger.logger - ERROR - Unhandled Exception: Traceback (most recent call last):
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\app.py", line 74, in query_travel_agent
    final_state = compiled_graph.invoke(initial_state)
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\venv\Lib\site-packages\langgraph\pregel\__init__.py", line 2844, in invoke
    for chunk in self.stream(
                 ~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<8 lines>...
        **kwargs,
        ^^^^^^^^^
    ):
    ^
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\venv\Lib\site-packages\langgraph\pregel\__init__.py", line 2534, in stream
    for _ in runner.tick(
             ~~~~~~~~~~~^
        [t for t in loop.tasks.values() if not t.writes],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<2 lines>...
        schedule_task=loop.accept_push,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ):
    ^
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\venv\Lib\site-packages\langgraph\pregel\runner.py", line 162, in tick
    run_with_retry(
    ~~~~~~~~~~~~~~^
        t,
        ^^
    ...<10 lines>...
        },
        ^^
    )
    ^
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\venv\Lib\site-packages\langgraph\pregel\retry.py", line 42, in run_with_retry
    return task.proc.invoke(task.input, config)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\venv\Lib\site-packages\langgraph\utils\runnable.py", line 623, in invoke
    input = context.run(step.invoke, input, config, **kwargs)
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\venv\Lib\site-packages\langgraph\utils\runnable.py", line 377, in invoke
    ret = self.func(*args, **kwargs)
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\backend\tools\report_writting_agent.py", line 43, in run
    response = self.llm.generate_reply(messages=[{"role": "user", "content": input_text}])
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\ganes_3ck5\DataScience\Gen_AI\Course_GenAI\Gen_AI_In-Depth\Agentic_AI_Agents\Deep_Web_Research_Agentic_System\venv\Lib\site-packages\pydantic\main.py", line 991, in __getattr__
    raise AttributeError(f'{type(self).__name__!r} object has no attribute {item!r}')
AttributeError: 'OllamaLLM' object has no attribute 'generate_reply'. Did you mean: '_generate_helper'?
During task with name 'report_writting_agent' and id '40f31b15-db92-70f5-6de7-f3109354d3ac'

